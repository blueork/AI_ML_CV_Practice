{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd475127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6294a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Installed\\ana\\envs\\kdd_task_1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'en/train-00000-of-00001.parquet', 'test': 'en/test-00000-of-00001.parquet', 'validation': 'en/validation-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/google-research-datasets/paws-x/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41efe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49401 entries, 0 to 49400\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         49401 non-null  int32 \n",
      " 1   sentence1  49401 non-null  object\n",
      " 2   sentence2  49401 non-null  object\n",
      " 3   label      49401 non-null  int64 \n",
      "dtypes: int32(1), int64(1), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e69fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9adaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 772/772 [36:19<00:00,  2.82s/it] \n",
      "Batches: 100%|██████████| 772/772 [35:17<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "sentences1 = df['sentence1'].tolist()\n",
    "sentences2 = df['sentence2'].tolist()\n",
    "\n",
    "emb1 = model.encode(sentences1, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
    "emb2 = model.encode(sentences2, batch_size=64, show_progress_bar=True, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff48d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([emb1, emb2, np.abs(emb1 - emb2), emb1 * emb2], axis=1)\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ba6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0026eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                              torch.tensor(y_train, dtype=torch.float32))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                            torch.tensor(y_val, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e8383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentencePairClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e64d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Acc=0.6071, F1=0.3500, AUC=0.6078\n",
      "Epoch 2: Val Acc=0.6119, F1=0.4457, AUC=0.6135\n",
      "Epoch 3: Val Acc=0.6063, F1=0.4549, AUC=0.6164\n",
      "Epoch 4: Val Acc=0.6156, F1=0.4302, AUC=0.6227\n",
      "Epoch 5: Val Acc=0.6198, F1=0.4320, AUC=0.6255\n",
      "Epoch 6: Val Acc=0.6210, F1=0.4446, AUC=0.6271\n",
      "Epoch 7: Val Acc=0.6274, F1=0.4288, AUC=0.6292\n",
      "Epoch 8: Val Acc=0.6232, F1=0.4582, AUC=0.6280\n",
      "Epoch 9: Val Acc=0.6191, F1=0.4659, AUC=0.6250\n",
      "Epoch 10: Val Acc=0.6252, F1=0.4457, AUC=0.6249\n",
      "Epoch 11: Val Acc=0.6273, F1=0.4354, AUC=0.6187\n",
      "Epoch 12: Val Acc=0.6096, F1=0.4742, AUC=0.6140\n",
      "Epoch 13: Val Acc=0.6230, F1=0.4561, AUC=0.6136\n",
      "Epoch 14: Val Acc=0.6218, F1=0.4391, AUC=0.6085\n",
      "Epoch 15: Val Acc=0.6228, F1=0.4538, AUC=0.6111\n",
      "Epoch 16: Val Acc=0.6126, F1=0.4748, AUC=0.6094\n",
      "Epoch 17: Val Acc=0.6100, F1=0.4728, AUC=0.6053\n",
      "Epoch 18: Val Acc=0.6255, F1=0.4283, AUC=0.6028\n",
      "Epoch 19: Val Acc=0.6171, F1=0.4564, AUC=0.6026\n",
      "Epoch 20: Val Acc=0.6258, F1=0.4370, AUC=0.6004\n",
      "Epoch 21: Val Acc=0.6147, F1=0.4697, AUC=0.6010\n",
      "Epoch 22: Val Acc=0.6118, F1=0.4495, AUC=0.5949\n",
      "Epoch 23: Val Acc=0.6037, F1=0.4828, AUC=0.5971\n",
      "Epoch 24: Val Acc=0.6263, F1=0.4619, AUC=0.6029\n",
      "Epoch 25: Val Acc=0.6088, F1=0.4656, AUC=0.5938\n",
      "Epoch 26: Val Acc=0.6095, F1=0.4613, AUC=0.5963\n",
      "Epoch 27: Val Acc=0.6178, F1=0.4577, AUC=0.5961\n",
      "Epoch 28: Val Acc=0.6020, F1=0.4712, AUC=0.5938\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 34\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, yb)\n\u001b[0;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SentencePairClassifier(input_dim=3072).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            probs = model(xb).squeeze()\n",
    "            preds = (probs >= 0.5).int()\n",
    "            y_true.extend(yb.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_prob.extend(probs.cpu().numpy())\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_prob)\n",
    "    }\n",
    "\n",
    "# Training\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xb).squeeze()\n",
    "        loss = criterion(output, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    val_metrics = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Val Acc={val_metrics['accuracy']:.4f}, \"\n",
    "          f\"F1={val_metrics['f1']:.4f}, AUC={val_metrics['roc_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478344a1",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdd_task_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
